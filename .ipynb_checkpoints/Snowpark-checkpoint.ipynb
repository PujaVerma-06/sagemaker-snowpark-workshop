{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "!pip install snowflake-snowpark-python==0.10.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install cachetools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pprint import pprint\n",
    "import re\n",
    "import datetime\n",
    "import io\n",
    "import joblib\n",
    "from joblib import dump\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Snowflake Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from snowflake.snowpark import (\n",
    "    Column,\n",
    "    DataFrame,\n",
    "    Session,\n",
    "    Window\n",
    ")\n",
    "\n",
    "import snowflake.snowpark\n",
    "from snowflake.snowpark import functions as f\n",
    "from snowflake.snowpark.types import IntegerType, StringType, StructType, DateType, StructField, MapType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "connection_parameters = {\n",
    "\"account\": \"\",\n",
    "\"user\": \"\",\n",
    "\"password\": \"\",\n",
    "\"role\": \"\",\n",
    "\"warehouse\": \"\",\n",
    "\"database\": \"\",\n",
    "\"schema\": \"\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "snowflake_conn_session = Session.builder.configs(connection_parameters).create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "snowflake_conn_session.sql(\"select current_warehouse(), current_database(), current_schema()\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "snow_df = snowflake_conn_session.table(\"Snowpark_dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "snow_df.schema.fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "snow_df.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "snow_df = snow_df.with_column('TARGET', f.when(f.col('CLASS') == 'good',1).otherwise(0))\n",
    "snow_df = snow_df.drop(f.col('CLASS'))\n",
    "\n",
    "snow_df.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "snow_df_train, snow_df_inf = snow_df.random_split([0.8, 0.2], seed=1234)\n",
    "\n",
    "snow_df_train.write.save_as_table('training_table', mode=\"overwrite\", create_temp_table=False)\n",
    "snow_df_inf.write.save_as_table('inference_table', mode=\"overwrite\", create_temp_table=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "session = Session.builder.configs(connection_parameters).create()\n",
    "session.add_packages('snowflake-snowpark-python', 'scikit-learn', 'pandas', 'numpy', 'joblib', 'cachetools')\n",
    "\n",
    "def save_file(session, model, path, dest_filename):\n",
    "    input_stream = io.BytesIO()\n",
    "    joblib.dump(model, input_stream)\n",
    "    session._conn.upload_stream(input_stream, path, dest_filename)\n",
    "    return \"successfully created file: \" + path\n",
    "\n",
    "def train_model(session: Session) -> str:\n",
    "    \n",
    "    \n",
    "    df_train = session.table('training_table')\n",
    "\n",
    "    df_train_pd = df_train.to_pandas()\n",
    "    \n",
    "    numerical_cols = list(df_train_pd.select_dtypes(['float64', 'int64']).columns)\n",
    "    categorical_cols = list(df_train_pd.drop('TARGET', axis=1).select_dtypes(['object']).columns)\n",
    "\n",
    "    X = df_train_pd.drop('TARGET', axis=1)\n",
    "    y = df_train_pd['TARGET']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1234)\n",
    "\n",
    "    numeric_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler())])\n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "        ('one_hot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numeric_transformer, numerical_cols),\n",
    "            ('cat', categorical_transformer, categorical_cols)])\n",
    "\n",
    "    rf_pipe = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                          ('classifier',  RandomForestClassifier(class_weight='balanced',\n",
    "                                                                 random_state=0))])\n",
    "\n",
    "    rf_clf = rf_pipe.fit(X_train, y_train)\n",
    "    \n",
    "    save_file(session, rf_clf, \"@SNOWFLAKESTAGE\", 'credit_g_model_2.joblib')\n",
    "\n",
    "    y_pred = rf_clf.predict(X_test)\n",
    "    return classification_report(y_test, y_pred)\n",
    "\n",
    "train_model_sp = f.sproc(train_model, replace=True, session=session)\n",
    "\n",
    "train_model_sp(session=session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from snowflake.snowpark.functions import udf\n",
    "session.add_import(\"@SNOWFLAKESTAGE/credit_g_model_2.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"create or replace stage udf\" +\\\n",
    "        \" copy_options = (on_error='skip_file')\"\n",
    "        \n",
    "session.sql(query).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cachetools\n",
    "import joblib\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from snowflake.snowpark.functions import udf\n",
    "\n",
    "@cachetools.cached(cache={})\n",
    "def read_file(filename):\n",
    "    import_dir = sys._xoptions.get(\"snowflake_import_directory\")\n",
    "    if import_dir:\n",
    "        with open(os.path.join(import_dir, filename), 'rb') as file:\n",
    "            m = joblib.load(file)\n",
    "    return m\n",
    "\n",
    "features = ['CHECKING_STATUS', 'DURATION', 'CREDIT_HISTORY', 'PURPOSE','CREDIT_AMOUNT', \n",
    "            'SAVINGS_STATUS', 'EMPLOYMENT','INSTALLMENT_COMMITMENT', 'PERSONAL_STATUS', \n",
    "            'THER_PARTIES', 'RESIDENCE_SINCE', 'PROPERTY_MAGNITUDE', 'AGE', \n",
    "            'OTHER_PAYMENT_PLANS', 'HOUSING', 'EXISTING_CREDITS', 'JOB', 'NUM_DEPENDENTS',\n",
    "            'OWN_TELEPHONE','FOREIGN_WORKER']\n",
    "\n",
    "@udf(name=\"predict\", is_permanent=True, stage_location=\"@udf\", replace=True, session=session)\n",
    "\n",
    "def predict(CHECKING_STATUS: str,\n",
    "            DURATION: int,\n",
    "            CREDIT_HISTORY: str,\n",
    "            PURPOSE: str,\n",
    "            CREDIT_AMOUNT: float,\n",
    "            SAVINGS_STATUS: str,\n",
    "            EMPLOYMENT: str,\n",
    "            INSTALLMENT_COMMITMENT: float,\n",
    "            PERSONAL_STATUS: str,\n",
    "            THER_PARTIES: str,\n",
    "            RESIDENCE_SINCE: float,\n",
    "            PROPERTY_MAGNITUDE: str,\n",
    "            AGE: str,\n",
    "            OTHER_PAYMENT_PLANS: str,\n",
    "            HOUSING: str,\n",
    "            EXISTING_CREDITS: float,\n",
    "            JOB: str,\n",
    "            NUM_DEPENDENTS: float,\n",
    "            OWN_TELEPHONE: str,\n",
    "            FOREIGN_WORKER: str) -> float:\n",
    "    model = read_file('credit_g_model_2.joblib')\n",
    "    row = pd.DataFrame([locals()], columns=features)\n",
    "    return model.predict(row)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snowflake.snowpark.functions import col\n",
    "\n",
    "inf_table = 'inference_table'\n",
    "\n",
    "snow_df_test = session.table(inf_table)\n",
    "snow_df_test.show(2)\n",
    "inputs = snow_df_test.drop(\"TARGET\")\n",
    "inputs.show(2)\n",
    "snow_df_results = snow_df_test.select(*inputs,\n",
    "                                      predict(*inputs).alias('PREDICTION'),\n",
    "                                      (col('TARGET')).alias('ACTUAL_LABEL'))\n",
    "#snow_df_results.to_pandas().head(20)\n",
    "snow_df_results.write.mode(\"overwrite\").save_as_table(\"CREDIT_G_PREDICTIONS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 2.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:eu-west-1:470317259841:image/sagemaker-data-science-38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
